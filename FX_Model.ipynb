{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae345cce-7b03-4dbd-9db4-f61cc8926ed0",
   "metadata": {},
   "source": [
    "# FX Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f14d9cf-36ed-42f2-a7e6-d0626dca3609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjour\n",
      "EURUSD - Regime actuel HMM: NEUTRAL\n",
      "GBPUSD - Regime actuel HMM: BEAR\n",
      "USDJPY - Regime actuel HMM: BEAR\n",
      "AUDUSD - Regime actuel HMM: BEAR\n",
      "USDCAD - Regime actuel HMM: BULL\n",
      "NZDUSD - Regime actuel HMM: BULL\n",
      "USDCHF - Regime actuel HMM: BEAR\n",
      "EURUSD - LSTM prediction: 0.0011166088679359523\n",
      "GBPUSD - LSTM prediction: 0.0002998146471783738\n",
      "USDJPY - LSTM prediction: -0.0002384990563740393\n",
      "AUDUSD - LSTM prediction: 0.00039111449797538887\n",
      "USDCAD - LSTM prediction: -0.0001782067108275945\n",
      "NZDUSD - LSTM prediction: 0.00045469550135865714\n",
      "USDCHF - LSTM prediction: 0.0007489377496386037\n",
      "EURUSD - XGBoost prediction: -0.00039665770557432555\n",
      "GBPUSD - XGBoost prediction: 0.0003090818782205896\n",
      "USDJPY - XGBoost prediction: -0.001510492116903454\n",
      "AUDUSD - XGBoost prediction: -6.228782659091394e-05\n",
      "USDCAD - XGBoost prediction: -0.00046114042696180924\n",
      "NZDUSD - XGBoost prediction: 0.0004201348928297418\n",
      "USDCHF - XGBoost prediction: -0.0008364078805686534\n",
      "\n",
      "Ensemble des predictions (LSTM + XGBoost + HMM)\n",
      "EURUSD - Ensemble: 0.00036 (HMM: NEUTRAL )\n",
      "GBPUSD - Ensemble: 0.000244 (HMM: BEAR )\n",
      "USDJPY - Ensemble: -0.0007 (HMM: BEAR )\n",
      "AUDUSD - Ensemble: 0.000132 (HMM: BEAR )\n",
      "USDCAD - Ensemble: -0.000384 (HMM: BULL )\n",
      "NZDUSD - Ensemble: 0.000525 (HMM: BULL )\n",
      "USDCHF - Ensemble: -3.5e-05 (HMM: BEAR )\n",
      "\n",
      "Rendements esperes mu (ensemble LSTM + XGBoost + HMM):\n",
      "[ 3.59975581e-04  2.43558610e-04 -6.99596469e-04  1.31530669e-04\n",
      " -3.83608283e-04  5.24898237e-04 -3.49880524e-05]\n",
      "\n",
      "Poids optimaux Markowitz (formule du cours avec contrainte rendement):\n",
      "EURUSD :  0.24744827896532545\n",
      "GBPUSD :  0.05255172103467447\n",
      "USDJPY :  0.05\n",
      "AUDUSD :  0.05000000000000002\n",
      "USDCAD :  0.05000000000000017\n",
      "NZDUSD :  0.49999999999999994\n",
      "USDCHF :  0.05000000000000013\n",
      "\n",
      "Exposant de Hurst moyen:  0.6552091827141099\n",
      "Regime de marche (Hurst):  TRENDING\n",
      "Facteur de levier:  1.3\n",
      "\n",
      "Poids finaux ajustes avec Hurst:\n",
      "EURUSD :  0.2474\n",
      "GBPUSD :  0.0526\n",
      "USDJPY :  0.05\n",
      "AUDUSD :  0.05\n",
      "USDCAD :  0.05\n",
      "NZDUSD :  0.5\n",
      "USDCHF :  0.05\n",
      "\n",
      "Sharpe Ratio Markowitz optimal:  0.022972591070944477\n",
      "Sharpe Ratio avec ajustement Hurst:  0.022972591070944477\n",
      "\n",
      "VaR 95% Markowitz optimal:  0.025439850352684843\n",
      "Expected Shortfall 95% Markowitz optimal:  0.03192913248546509\n",
      "\n",
      "VaR 95% avec ajustement Hurst:  0.02543985035268484\n",
      "Expected Shortfall 95% avec ajustement Hurst:  0.031929132485465084\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import minimize\n",
    "from hmmlearn import hmm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"bonjour\")\n",
    "\n",
    "pairs = ['EURUSD', 'GBPUSD', 'USDJPY', 'AUDUSD', 'USDCAD', 'NZDUSD', 'USDCHF']\n",
    "dates = pd.date_range(start='2015-01-01', end='2024-12-31', freq='D')\n",
    "n = len(dates)\n",
    "n_pairs = len(pairs)\n",
    "\n",
    "data_dict = {}\n",
    "for i, pair in enumerate(pairs):\n",
    "    np.random.seed(42 + i)\n",
    "    trend = np.linspace(1.10 + i*0.05, 1.20 + i*0.05, n)\n",
    "    noise = np.random.normal(0, 0.015 + i*0.003, n)\n",
    "    close = trend + noise\n",
    "    \n",
    "    cycle = 0.05 * np.sin(2 * np.pi * np.arange(n) / (252 * 2 + i * 50))\n",
    "    close = close + cycle\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Open': close * (1 + np.random.normal(0, 0.003, n)),\n",
    "        'High': close * (1 + np.abs(np.random.normal(0, 0.006, n))),\n",
    "        'Low': close * (1 - np.abs(np.random.normal(0, 0.006, n))),\n",
    "        'Close': close,\n",
    "    }, index=dates)\n",
    "    \n",
    "    data_dict[pair] = df\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "    df['Return_1d'] = df['Return'].shift(1)\n",
    "    df['Return_5d'] = df['Close'].pct_change(5)\n",
    "    \n",
    "    df['SMA_21'] = df['Close'].rolling(21).mean()\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26).mean()\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    \n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['RealizedVol_21d'] = df['Return'].rolling(21).std() * np.sqrt(252)\n",
    "    \n",
    "    df['Target_Direction'] = (df['Return'].shift(-1) > 0).astype(int)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "for pair in pairs:\n",
    "    data_dict[pair] = create_features(data_dict[pair])\n",
    "\n",
    "\n",
    "#Méthode R/S (Rescaled Range) pour calculer l'exposant de Hurst\n",
    "#Plus robuste que la méthode des moments\n",
    "#H doit être entre 0 et 1\n",
    "# Peters 1994\n",
    "def calculate_hurst_exponent(ts, max_lag=20):\n",
    "    n = len(ts)\n",
    "    \n",
    "    if n < 20:\n",
    "        return 0.5\n",
    "    \n",
    "    lags = range(2, min(max_lag, n // 2))\n",
    "    \n",
    "    tau = []\n",
    "    for lag in lags:\n",
    "        n_chunks = n // lag\n",
    "        if n_chunks == 0:\n",
    "            continue\n",
    "        \n",
    "        rs_values = []\n",
    "        for i in range(n_chunks):\n",
    "            chunk = ts[i*lag:(i+1)*lag]\n",
    "            if len(chunk) < 2:\n",
    "                continue\n",
    "            \n",
    "            mean_chunk = np.mean(chunk)\n",
    "            deviations = chunk - mean_chunk\n",
    "            cumsum_dev = np.cumsum(deviations)\n",
    "            \n",
    "            R = np.max(cumsum_dev) - np.min(cumsum_dev)\n",
    "            S = np.std(chunk)\n",
    "            \n",
    "            if S > 0:\n",
    "                rs_values.append(R / S)\n",
    "        \n",
    "        if len(rs_values) > 0:\n",
    "            tau.append(np.mean(rs_values))\n",
    "    \n",
    "    if len(tau) < 2:\n",
    "        return 0.5\n",
    "    \n",
    "    lags_array = np.array(list(lags)[:len(tau)])\n",
    "    tau_array = np.array(tau)\n",
    "    \n",
    "    if np.any(tau_array <= 0):\n",
    "        return 0.5\n",
    "    \n",
    "    log_lags = np.log(lags_array)\n",
    "    log_tau = np.log(tau_array)\n",
    "    \n",
    "    coeffs = np.polyfit(log_lags, log_tau, 1)\n",
    "    H_hat = coeffs[0]\n",
    "    \n",
    "    H_hat = np.clip(H_hat, 0.0, 1.0)\n",
    "    \n",
    "    return H_hat\n",
    "\n",
    "def rolling_hurst(series, window=100):\n",
    "    hurst_values = []\n",
    "    for i in range(window, len(series)):\n",
    "        subset = series[i-window:i].values\n",
    "        try:\n",
    "            h = calculate_hurst_exponent(subset)\n",
    "            hurst_values.append(h)\n",
    "        except:\n",
    "            hurst_values.append(np.nan)\n",
    "    \n",
    "    hurst_series = pd.Series([np.nan] * window + hurst_values, index=series.index)\n",
    "    return hurst_series\n",
    "\n",
    "for pair in pairs:\n",
    "    data_dict[pair]['Hurst'] = rolling_hurst(data_dict[pair]['Close'], window=100)\n",
    "    data_dict[pair].dropna(inplace=True)\n",
    "\n",
    "\n",
    "# ML models first HMM for the regime detection\n",
    "\n",
    "hmm_regimes = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    df = data_dict[pair]\n",
    "    \n",
    "    returns = df['Return'].values.reshape(-1, 1)\n",
    "    \n",
    "    returns_clean = returns[~np.isnan(returns).any(axis=1)]\n",
    "    returns_clean = returns_clean[~np.isinf(returns_clean).any(axis=1)]\n",
    "    \n",
    "    model = hmm.GaussianHMM(n_components=3, covariance_type=\"diag\", n_iter=100, random_state=42)\n",
    "    model.fit(returns_clean)\n",
    "    \n",
    "    hidden_states = model.predict(returns_clean)\n",
    "    \n",
    "    hidden_states_full = np.full(len(df), -1)\n",
    "    valid_indices = ~np.isnan(returns).flatten() & ~np.isinf(returns).flatten()\n",
    "    hidden_states_full[valid_indices] = hidden_states\n",
    "    \n",
    "    data_dict[pair]['HMM_Regime'] = hidden_states_full\n",
    "    \n",
    "    regime_means = []\n",
    "    for i in range(3):\n",
    "        regime_returns = df[hidden_states_full == i]['Return']\n",
    "        if len(regime_returns) > 0:\n",
    "            regime_means.append(regime_returns.mean())\n",
    "        else:\n",
    "            regime_means.append(0)\n",
    "    \n",
    "    regime_order = np.argsort(regime_means)\n",
    "    regime_map = {regime_order[0]: 'BEAR', regime_order[1]: 'NEUTRAL', regime_order[2]: 'BULL', -1: 'NEUTRAL'}\n",
    "    \n",
    "    data_dict[pair]['HMM_Regime_Label'] = data_dict[pair]['HMM_Regime'].map(regime_map)\n",
    "    \n",
    "    current_regime = data_dict[pair]['HMM_Regime_Label'].iloc[-1]\n",
    "    hmm_regimes[pair] = current_regime\n",
    "    \n",
    "    print(pair, \"- Regime actuel HMM:\", current_regime)\n",
    "\n",
    "# LSTM à améliorer car dépend du HMM et peut contenir du data leakage \n",
    "\n",
    "feature_cols = ['Return_1d', 'Return_5d', 'SMA_21', 'MACD', 'RSI', \n",
    "                'RealizedVol_21d', 'Hurst']\n",
    "\n",
    "lstm_predictions = {}\n",
    "lookback = 30\n",
    "\n",
    "for pair in pairs:\n",
    "    df = data_dict[pair]\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['Target_Direction'].values\n",
    "    \n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train = X[:split_idx]\n",
    "    X_test = X[split_idx:]\n",
    "    y_train = y[:split_idx]\n",
    "    y_test = y[split_idx:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    def create_sequences(X, y, lookback):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - lookback):\n",
    "            Xs.append(X[i:i+lookback])\n",
    "            ys.append(y[i+lookback])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "    \n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, lookback)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, lookback)\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=(lookback, X_train.shape[1])),\n",
    "        Dropout(0.2),\n",
    "        LSTM(16, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    y_pred_proba = model.predict(X_test_seq, verbose=0)\n",
    "    \n",
    "    expected_return = (y_pred_proba.mean() - 0.5) * 2 * df['RealizedVol_21d'].mean() / np.sqrt(252)\n",
    "    \n",
    "    lstm_predictions[pair] = expected_return\n",
    "    \n",
    "    print(pair, \"- LSTM prediction:\",expected_return)\n",
    "\n",
    "xgb_predictions = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    df = data_dict[pair]\n",
    "    \n",
    "    X = df[feature_cols]\n",
    "    y = df['Target_Direction']\n",
    "    \n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train = X.iloc[:split_idx]\n",
    "    X_test = X.iloc[split_idx:]\n",
    "    y_train = y.iloc[:split_idx]\n",
    "    y_test = y.iloc[split_idx:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred_proba = xgb_model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    expected_return = (y_pred_proba[:, 1].mean() - 0.5) * 2 * df['RealizedVol_21d'].mean() / np.sqrt(252)\n",
    "    \n",
    "    xgb_predictions[pair] = expected_return\n",
    "    \n",
    "    print(pair, \"- XGBoost prediction:\", expected_return)\n",
    "\n",
    "\n",
    "# Combinaison des 3 modèles précédents en accord avec le papier de Liu\n",
    "print(\"\\nEnsemble des predictions (LSTM + XGBoost + HMM)\")\n",
    "\n",
    "ensemble_predictions = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    lstm_pred = lstm_predictions[pair]\n",
    "    xgb_pred = xgb_predictions[pair]\n",
    "    \n",
    "    hmm_regime = hmm_regimes[pair]\n",
    "    if hmm_regime == 'BULL':\n",
    "        hmm_boost = 1.2\n",
    "    elif hmm_regime == 'BEAR':\n",
    "        hmm_boost = 0.8\n",
    "    else:\n",
    "        hmm_boost = 1.0\n",
    "    \n",
    "    ensemble_pred = (0.5 * lstm_pred + 0.5 * xgb_pred) * hmm_boost\n",
    "    \n",
    "    ensemble_predictions[pair] = ensemble_pred\n",
    "    \n",
    "    print(pair, \"- Ensemble:\", round(ensemble_pred, 6), \"(HMM:\", hmm_regime, \")\")\n",
    "\n",
    "\n",
    "returns_matrix = pd.DataFrame({pair: data_dict[pair]['Return'] for pair in pairs})\n",
    "returns_matrix = returns_matrix.dropna()\n",
    "\n",
    "Sigma = returns_matrix.cov().values\n",
    "mu = np.array([ensemble_predictions[pair] for pair in pairs])\n",
    "\n",
    "print(\"\\nRendements esperes mu (ensemble LSTM + XGBoost + HMM):\")\n",
    "print(mu)\n",
    "\n",
    "\n",
    "#Formule exacte du cours: min w^T Sigma w\n",
    "def objective_function(weight_vector, mat_corr):\n",
    "    return weight_vector @ mat_corr @ weight_vector\n",
    "\n",
    "# Optimisation de Markowitz du cours\n",
    "#min w^T Sigma w s.c. w^T 1 = 1, sum(w_i * r_i) >= r_target\n",
    "\n",
    "def markowitz_optimization(vec_returns, mat_corr):\n",
    "    n = len(vec_returns)\n",
    "    initial_guess = np.ones(n) / n\n",
    "    bounds = [(0.05, 0.5) for _ in range(n)]\n",
    "    \n",
    "    target_return = np.mean(vec_returns[vec_returns > 0]) if np.any(vec_returns > 0) else np.mean(vec_returns)\n",
    "    \n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},\n",
    "        {'type': 'ineq', 'fun': lambda w: np.dot(w, vec_returns) - target_return}\n",
    "    ]\n",
    "    \n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_guess,\n",
    "        args=(mat_corr,),\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "poids_optimaux = markowitz_optimization(mu, Sigma)\n",
    "\n",
    "print(\"\\nPoids optimaux Markowitz (formule du cours avec contrainte rendement):\")\n",
    "for i, pair in enumerate(pairs):\n",
    "    print(pair, \": \", poids_optimaux[i])\n",
    "\n",
    "\n",
    "# Ajustement en fonction de hurst\n",
    "# en fonction de si le marché a tendance à persister dans une tendance ou non \n",
    "hurst_mean = np.mean([data_dict[pair]['Hurst'].mean() for pair in pairs])\n",
    "\n",
    "print(\"\\nExposant de Hurst moyen: \", hurst_mean)\n",
    "\n",
    "if hurst_mean > 0.55:\n",
    "    regime = \"TRENDING\"\n",
    "    leverage_factor = 1.3\n",
    "elif hurst_mean < 0.45:\n",
    "    regime = \"MEAN REVERTING\"\n",
    "    leverage_factor = 0.7\n",
    "else:\n",
    "    regime = \"BROWNIAN\"\n",
    "    leverage_factor = 1.0\n",
    "\n",
    "print(\"Regime de marche (Hurst): \", regime)\n",
    "print(\"Facteur de levier: \", leverage_factor)\n",
    "\n",
    "omega_final = poids_optimaux * leverage_factor\n",
    "omega_final = omega_final / np.sum(omega_final)\n",
    "\n",
    "print(\"\\nPoids finaux ajustes avec Hurst:\")\n",
    "for i, pair in enumerate(pairs):\n",
    "    print(pair, \": \", round(omega_final[i], 4))\n",
    "\n",
    "\n",
    "# juste quelques métriques pour voir le fonctionnement\n",
    "def calculate_sharpe_ratio(returns):\n",
    "    n = len(returns)\n",
    "    mean_return = np.sum(returns) / n\n",
    "    variance = np.sum(returns**2) / n\n",
    "    if variance == 0:\n",
    "        return 0\n",
    "    sharpe = mean_return / np.sqrt(variance)\n",
    "    return sharpe\n",
    "\n",
    "def calculate_var(returns, alpha=0.95):\n",
    "    return -np.percentile(returns, (1-alpha)*100)\n",
    "\n",
    "def calculate_expected_shortfall(returns, alpha=0.95):\n",
    "    var_alpha = calculate_var(returns, alpha)\n",
    "    losses = -returns\n",
    "    tail_losses = losses[losses >= var_alpha]\n",
    "    if len(tail_losses) == 0:\n",
    "        return var_alpha\n",
    "    return np.mean(tail_losses)\n",
    "\n",
    "portfolio_returns_optimal = returns_matrix.values @ poids_optimaux\n",
    "portfolio_returns_final = returns_matrix.values @ omega_final\n",
    "sharpe_optimal = calculate_sharpe_ratio(portfolio_returns_optimal)\n",
    "sharpe_final = calculate_sharpe_ratio(portfolio_returns_final)\n",
    "var_95_optimal = calculate_var(portfolio_returns_optimal, 0.95)\n",
    "es_95_optimal = calculate_expected_shortfall(portfolio_returns_optimal, 0.95)\n",
    "var_95_final = calculate_var(portfolio_returns_final, 0.95)\n",
    "es_95_final = calculate_expected_shortfall(portfolio_returns_final, 0.95)\n",
    "\n",
    "print(\"\\nSharpe Ratio Markowitz optimal: \", sharpe_optimal)\n",
    "print(\"Sharpe Ratio avec ajustement Hurst: \", sharpe_final)\n",
    "\n",
    "print(\"\\nVaR 95% Markowitz optimal: \", var_95_optimal)\n",
    "print(\"Expected Shortfall 95% Markowitz optimal: \", es_95_optimal)\n",
    "\n",
    "print(\"\\nVaR 95% avec ajustement Hurst: \", var_95_final)\n",
    "print(\"Expected Shortfall 95% avec ajustement Hurst: \", es_95_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe3862-ef7d-44c5-b561-614e9e3bd4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44718f-87ba-430d-b16f-b8cf3bbb5650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
